# Parking-Space-Detection

Parking space detection is a key component of intelligent transportation systems aimed at alleviating urban congestion and improving parking efficiency. This project investigates the application of Vision Transformers (ViTs) in comparison with traditional Convolutional Neural Networks (CNNs) for parking occupancy detection. Our goal was to develop a few-shot learning model capable of accurate segmentation using minimal labeled data, making it scalable to new parking environments without extensive annotation. We utilized the ACPDS (fully annotated) and PKLot (partially annotated) datasets and applied preprocessing to convert classification-style data into pixel-level segmentation maps. A pretrained DINOv2 ViT model was used as the feature extractor, followed by experimentation with both linear probing and a SegFormer-style decoder head for segmentation. The results show that the ViT-based architecture significantly outperforms CNN baselines, achieving high F1 scores even under challenging conditions such as occlusions, varying weather, and camera distortions. This work highlights the robustness, scalability, and practicality of Vision Transformers for real-world parking space detection systems. 
